# AI
Код загружает знаменитый набор данных Iris, который содержит измерения для 150 цветков ириса, разделенных на три разных вида. Этот набор данных широко используется для задач классификации в машинном обучении. В моем коде реализован алгоритм простого классификатора на основе расстояний.

## Загрузка и подготовка данных:
Сначала код загружает набор данных Iris с помощью load_iris из sklearn.datasets, затем разделяет данные на признаки X и метки классов y.
## Разделение данных:
Данные разделяются на обучающую (X_train и y_train) и параметрическую (X_param и y_param) выборки для каждого класса. Параметрическая выборка очень мала (2% от всего набора данных) и будет использоваться для вычисления средних расстояний до каждого класса.
## Вычисление средних расстояний:
С помощью функции cdist из SciPy вычисляются Евклидовы расстояния от каждого объекта обучающей выборки до объектов параметрической выборки каждого класса. Для каждого объекта обучающей выборки сохраняется среднее расстояние до объектов каждого класса в массиве class_similarities.
## Принятие решения:
Функция decision_rule определяет класс объекта на основе минимального среднего расстояния до параметрических объектов классов.
## Оценка качества:
Распознавание выполняется с использованием этого правила решений, и точность классификации рассчитывается как отношение правильно классифицированных объектов к общему числу объектов в обучающей выборке.
## Матрица ошибок:
С помощью confusion_matrix из sklearn.metrics строится матрица ошибок, которая показывает, как классы были предсказаны по сравнению с их истинными значениями.

Закомментированный код в конце предназначен для вывода подробной информации о результатах классификации для каждого объекта, но он закомментирован и в текущей версии кода не выполняется.

Этот код является хорошим примером простой классификации в машинном обучении. Он использует базовые концепции измерения расстояния и правила ближайшего среднего для классификации объектов. Этот подход может быть полезен для понимания основ машинного обучения, но в реальных приложениях часто используются более продвинутые методы, такие как нейронные сети, случайные леса или поддерживающие векторные машины для достижения более высокой точности.
